{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx5W-R-ICs_5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])"
      ],
      "metadata": {
        "id": "PXKQl-RWpl74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgmJnWoN4Mm5",
        "outputId": "2e608b57-7efb-4c38-8d2b-44dac8cb60c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to cifar100_data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:02<00:00, 67727409.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting cifar100_data/cifar-100-python.tar.gz to cifar100_data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "dataset_root = 'cifar100_data'\n",
        "trainset = datasets.CIFAR100(\n",
        "    dataset_root,\n",
        "    train=True,\n",
        "    transform=data_transforms,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "testset = datasets.CIFAR100(\n",
        "    dataset_root,\n",
        "    train=False,\n",
        "    transform=data_transforms,\n",
        "    download=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNhl4k1845jr"
      },
      "outputs": [],
      "source": [
        "training_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "testing_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM3uRZDCD06i"
      },
      "outputs": [],
      "source": [
        "class MyCustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCustomCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size=3)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=3)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size=3)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.maxpool3 = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 2 * 2, 512)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(512, 100)  # 100 classes for CIFAR-100\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.maxpool1(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.maxpool2(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.relu3(out)\n",
        "        out = self.maxpool3(out)\n",
        "\n",
        "\n",
        "        out = torch.flatten(out, 1)\n",
        "\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu4(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w13ZFIeh5EVR"
      },
      "outputs": [],
      "source": [
        "num_epochs = 50 #should be at least 30\n",
        "model = MyCustomCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3-UbS3d6AUw",
        "outputId": "900c1642-6bfd-4346-dbd4-22b7b3ac7dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:27<00:00, 57.26it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 74.84it/s]\n",
            "100%|██████████| 1563/1563 [00:22<00:00, 71.03it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 75.32it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 76.06it/s]\n",
            "100%|██████████| 1563/1563 [00:21<00:00, 74.16it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 75.52it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 76.25it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 74.69it/s]\n",
            "100%|██████████| 1563/1563 [00:21<00:00, 72.30it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 76.36it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 74.80it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 75.76it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 75.21it/s]\n",
            "100%|██████████| 1563/1563 [00:21<00:00, 73.96it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 74.46it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 77.05it/s]\n",
            "100%|██████████| 1563/1563 [00:21<00:00, 73.81it/s]\n",
            "100%|██████████| 1563/1563 [00:21<00:00, 74.03it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 76.13it/s]\n",
            "100%|██████████| 1563/1563 [00:21<00:00, 73.97it/s]\n",
            "100%|██████████| 1563/1563 [00:21<00:00, 71.76it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 76.90it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 74.75it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 75.06it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 77.71it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 74.65it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 75.02it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 77.28it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 75.32it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 74.61it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 76.80it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 75.85it/s]\n",
            "100%|██████████| 1563/1563 [00:21<00:00, 72.11it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 77.38it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 74.95it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 74.84it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 77.70it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 74.59it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 74.99it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 76.83it/s]\n",
            "100%|██████████| 1563/1563 [00:21<00:00, 73.14it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 74.61it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 77.85it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 74.95it/s]\n",
            "100%|██████████| 1563/1563 [00:21<00:00, 71.37it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 77.85it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 75.32it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 75.48it/s]\n",
            "100%|██████████| 1563/1563 [00:20<00:00, 77.71it/s]\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for step, (images, labels) in enumerate(tqdm(training_loader)):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "torch.save(model.state_dict(), 'best_model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1LmCUuo6Mdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebffe49d-64b9-4eb6-9ea3-da91807b7499"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('best_model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRlVZcd16Mrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6d1bcc7-5016-4ec5-e678-1e28fba04e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:03<00:00, 83.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/50]: Accuracy = 45.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for step, (images, labels) in enumerate(tqdm(testing_loader)):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "\n",
        "print(f'Epoch [{epoch+1}/{num_epochs}]: Accuracy = {accuracy * 100:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}