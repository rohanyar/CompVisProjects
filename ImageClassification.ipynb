{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZpbF-iN3fcd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCTUnpv93hhX"
      },
      "source": [
        "Part 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR6rr06q4wEH"
      },
      "source": [
        "Resize the size of all images to a unanimous value (224, 224). Convert PIL image objects into Tensors.\n",
        "Normalize the tensor values based on the mean and standard deviation of the RGB values of all the\n",
        "images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAk0X9wO3km4"
      },
      "outputs": [],
      "source": [
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45jYze2P41GK"
      },
      "source": [
        "Create an object of torchvision.datasets.CIFAR100 to get the training and testing set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgmJnWoN4Mm5",
        "outputId": "f8017118-1a14-4f5b-e5b2-22aaf1a35c67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to cifar100_data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169001437/169001437 [00:03<00:00, 48565640.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting cifar100_data/cifar-100-python.tar.gz to cifar100_data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "dataset_root = 'cifar100_data'\n",
        "trainset = datasets.CIFAR100(\n",
        "    dataset_root,\n",
        "    train=True,\n",
        "    transform=data_transforms,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "testset = datasets.CIFAR100(\n",
        "    dataset_root,\n",
        "    train=False,\n",
        "    transform=data_transforms,\n",
        "    download=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwm9wdxw46FW"
      },
      "source": [
        "Create a data loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNhl4k1845jr"
      },
      "outputs": [],
      "source": [
        "training_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "testing_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt0PM-U37l_F"
      },
      "source": [
        "Load a VGG16 network with pretrained ImageNet weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7W9bYmt7mSJ",
        "outputId": "187cf0c9-3147-482a-8222-ad3cd608fea9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:06<00:00, 80.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = models.vgg16(pretrained = True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UujjAx6S7w55"
      },
      "source": [
        "Extract the number of input features for the last fully connected layer of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-V8ojl37yPe"
      },
      "outputs": [],
      "source": [
        "num_in_ftrs = model.classifier[6].in_features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnK4bHOP7yqf"
      },
      "source": [
        "Replace the last fully connected layer with a new layer. The new layer has the same number of input\n",
        "features as the original network but the number of outputs should be equal to the number of classes in\n",
        "the CIFAR100 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-ViC5Yt7zFp"
      },
      "outputs": [],
      "source": [
        "num_cls = 100\n",
        "model.classifier[6] = nn.Linear(num_in_ftrs, num_cls) # num_cls is the number of classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFal89Jv7zzc"
      },
      "source": [
        "We are using pretrained weights from the ImageNet dataset. The last layer of VGG16 has been replaced\n",
        "for fitting with our dataset (CIFAR100). Except for the new last layer, weights from other layers need to\n",
        "be frozen. It means that these weights will not be updated during the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0aj-PNe70Lr"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters(): # freeze all the layers\n",
        "  param.requires_grad = False\n",
        "for param in model.classifier[6].parameters(): # unfreeze the last linear layer.\n",
        "  param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGYdFRR789H6"
      },
      "source": [
        "Set the number of epochs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4pCq9oV89X6"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXavXd7p89k6"
      },
      "source": [
        "Move the model to GPU (if available):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtfQrzO989zz"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRsp9JLr89_S"
      },
      "source": [
        "Define a loss function for evaluating the trained model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz0L9oSy8-Yx"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijz8Y79h8-1w"
      },
      "source": [
        "Create an optimizer with an initial learning rate and momentum:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yITTv_U8_FF"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSk97HmG8_Zm"
      },
      "source": [
        "Create a scheduler to control the way that learning rate changes during the training process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVk9F8_D8_wH"
      },
      "outputs": [],
      "source": [
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1un_c_Ge-rr1"
      },
      "source": [
        "Iterate over the epochs and save the best model weights. Basically, the best model can achieve the best\n",
        "accuracy during the iteration. In every iteration, we get a mini-batch of images and their corresponding\n",
        "labels. Use zero_grad() to reset the calculated gradients. Use the current model weights for predication\n",
        "and backpropagate the prediction loss. After iterating over all batches and if we are in the training phase,\n",
        "we need to run scheduler.step() to update the scheduler status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uyt0O7VH-r8O",
        "outputId": "3d1b387b-6987-4d8a-8662-6cee92fbcb0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [05:31<00:00,  1.18it/s]\n",
            "100%|██████████| 391/391 [05:25<00:00,  1.20it/s]\n",
            "100%|██████████| 391/391 [05:24<00:00,  1.20it/s]\n",
            "100%|██████████| 391/391 [05:25<00:00,  1.20it/s]\n",
            "100%|██████████| 391/391 [05:28<00:00,  1.19it/s]\n",
            "100%|██████████| 391/391 [05:26<00:00,  1.20it/s]\n",
            "100%|██████████| 391/391 [05:26<00:00,  1.20it/s]\n",
            "100%|██████████| 391/391 [05:24<00:00,  1.20it/s]\n",
            "100%|██████████| 391/391 [05:25<00:00,  1.20it/s]\n",
            "100%|██████████| 391/391 [05:24<00:00,  1.21it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for images, labels in tqdm(training_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images.cuda())\n",
        "        loss = criterion(outputs, labels.cuda())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFXi12jt-sHf"
      },
      "source": [
        "The testing process is very similar to the training process except that there is no need to backpropagate\n",
        "the loss. For testing the model, first, you need to prepare the model in the same way that we prepared it\n",
        "for the training process and load the best model that we saved in the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i7fk5dh-sVd",
        "outputId": "b049f674-0bfa-4ed3-f808-c56f55a94dad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('best_model.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3pklD4U-sga"
      },
      "source": [
        "After loading the model weights, set the model to evaluation mode. Then go through the test set, and\n",
        "predict the category of images, and compute the number of correctly classified images and the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0RXrh_g-suH",
        "outputId": "c81af8e3-f0f5-4803-d2f8-e278f07e1f9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [01:03<00:00,  4.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/10]: Accuracy = 59.38%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(testing_loader):\n",
        "        outputs = model(images.cuda())\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.cuda()).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "\n",
        "print(f'Epoch [{epoch+1}/{num_epochs}]: Accuracy = {accuracy * 100:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
